<center><h1>图像视频编解码实验报告</h1></center>

<center><h6>范逍宇 2019013273</h6></center>

### 一、离散余弦变换。

首先将 lena 图片转为灰度图：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704081727587.png" alt="image-20220704081727587" style="zoom:50%;" />

对图片分别进行 1D, 2D, 分块 2D 的离散余弦变换，计算公式如下：

1D:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704082328969.png" alt="image-20220704082328969" style="zoom:67%;" />

2D:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704082359499.png" alt="image-20220704082359499" style="zoom:67%;" />

还原后的图片如下：

1D:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704081854119.png" alt="image-20220704081854119" style="zoom:50%;" />

2D:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704081916341.png" alt="image-20220704081916341" style="zoom:50%;" />

2D-block:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704081944436.png" alt="image-20220704081944436" style="zoom:50%;" />

可以看到，三种方式都机会完美地还原了原图，信噪比和运行时间分别如下：

|      | 1D      | 2D      | 2D-block |
| ---- | ------- | ------- | -------- |
| PSNR | 313.088 | 315.259 | 315.492  |
| Time | 0.0115  | 0.0089  | 0.0779   |

三种方式都具有很高的信噪比，可以认为几乎完美地还原了原图像。

根据算法进行复杂度分析，1D-DCT 的时间复杂度为 $O(2N^2)$，2D-DCT 的时间复杂度为 $O(N^4)$，2D-block-DCT 的时间复杂度为 $O(64N^2)$，显然 2D-DCT 的时间复杂度更高，但是实验结果却恰恰相反，这是因为本次实验使用 python 完成，而 numpy 的向量运算会大大减少运算时间，且 python 的底层逻辑难以得知，因此运行时间并不能准确的反映算法的时间复杂度，同时在 N 较小时常数较大同样会让运算时间大大延长。

尝试使用 1/4, 1/16, 1/64 的系数进行还原，其中 1D-DCT 的系数选取方式如下：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704083205564.png" alt="image-20220704083205564" style="zoom:67%;" />

其他两种方式直接选取左上角正方形区域的系数，其余系数直接补零，重复上述实验过程，得到的结果如下：

```
ratio: 1/4
Time of 1D-DCT: 0.011773824691772461
PSNR of 1D-DCT: 36.23451875078837
Time of 2D-DCT: 0.008972406387329102
PSNR of 2D-DCT: 36.23451875078837
Time of 2D-Block-DCT: 0.08886408805847168
PSNR of 2D-Block-DCT: 34.883867248072704
ratio: 1/16
Time of 1D-DCT: 0.007333993911743164
PSNR of 1D-DCT: 29.92222087337108
Time of 2D-DCT: 0.004986286163330078
PSNR of 2D-DCT: 29.92222087337108
Time of 2D-Block-DCT: 0.07120776176452637
PSNR of 2D-Block-DCT: 28.216171869441776
ratio: 1/64
Time of 1D-DCT: 0.0056917667388916016
PSNR of 1D-DCT: 25.864159071046267
Time of 2D-DCT: 0.004982471466064453
PSNR of 2D-DCT: 25.864159071046267
Time of 2D-Block-DCT: 0.07111644744873047
PSNR of 2D-Block-DCT: 23.67167604705525
```

可以看到，对于三种方式，减少系数都会大大降低信噪比，而运行时间变化不大。这是容易理解的，丢弃系数意味着信息的丢失，丢弃的系数越多，越难以还原真实的图像。

下面是 2D-DCT 选取 1/64 个系数还原出的图像：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704083602480.png" alt="image-20220704083602480" style="zoom:67%;" />

可以看出系数过少会导致画面出现明显的噪点和失真。

### 二、量化。

在上一步的基础上，对基于块的 2D-DCT 进行量化，首先使用 Q 量化矩阵，量化后还原的图片如下：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704075254156.png" alt="image-20220704075254156" style="zoom:50%;" />

PSNR=36.099，与量化之前相比，信噪比显著下降。

使用 aQ 进行量化，其中 a 的取值范围为 [0.1, 2)，以 0.1 为步长，做出 PSNR 随 a 变化的折线图如下：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704075804853.png" alt="image-20220704075804853" style="zoom:67%;" />

可以看到，随着 a 的不断增大，PSNR 在不断减小，这是容易理解的，a 越大，量化的区间越大，DCT 的系数的舍入误差越大，信噪比也就越小。

事实上，我们可以观察离散余弦变化的系数的大小来设计更好的量化矩阵，如下是离散余弦变换系数的可视化：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704080138731.png" alt="image-20220704080138731" style="zoom:50%;" />

可以看到，系数的较大值集中分布在左上角，而且靠近两边和靠近对角线的部分系数较大，我们假设较大的系数会对图片的还原产生较大的影响，于是我们希望尽可能精细地量化系数较大的部分，对其他部分则比较宽松，对于量化矩阵来说，这表示我们需要为希望精细量化的部分分配较小的值，于是，综合考虑系数距离对角线和边线和坐标原点的距离，我们可以得到如下的量化矩阵公式：

```python
for i in range(8):
        for j in range(8):
            My[i][j] = max(int(0.4*(0.4*(i**2+j**2)+0.5*(0.2*min(i,j)+0.7*abs(i-j))**2)),1)  
```

由上述公式产生的量化矩阵的系数为：

```python
My = [[1, 1, 1, 2, 4, 6, 9, 12], [1, 1, 1, 2, 3, 5, 8, 11], [1, 1, 1, 2, 3, 5, 8, 11], [2, 2, 2, 2, 4, 6, 8, 11], [4, 3, 3, 4, 5, 7, 9, 12], [6, 5, 5, 6, 7, 8, 10, 12], [9, 8, 8, 8, 9, 10, 11, 14], [12, 11, 11, 11, 12, 12, 14, 16]]
```

经过实验，这组量化矩阵的系数产生了很好的效果，这里选取了包括 lena 在内的三张图片进行验证，另外两张图片分别为：

child:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704080837109.png" alt="image-20220704080837109" style="zoom:50%;" />

lake:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704080855776.png" alt="image-20220704080855776" style="zoom:50%;" />

分别使用 Cannon, Nikon, Q, My 四种量化矩阵对上述三张图片进行量化，对于不同的 a，得到的 PSNR 折线图如下：

lena:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704081121933.png" alt="image-20220704081121933" style="zoom:67%;" />

child:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704081143967.png" alt="image-20220704081143967" style="zoom:67%;" />

lake:

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704081212486.png" alt="image-20220704081212486" style="zoom:67%;" />

可以看到，对于三张图片，这种新的量化矩阵都取得了更好的效果，说明这种简单的基于 DCT 系数大小分配量化精细程度的思想是行之有效的。

事实上，如果有大量的图片作为训练集，可以对于这些图片统计它们的 DCT 系数绝对值的大小，这样就不需要人工设计量化矩阵，而是直接根据统计结果学习出自然的量化矩阵。

### 三、运动估计。

在视频初始帧中选定一个 16×16 的像素块作为目标像素块进行跟踪，选择的像素块如下：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704071659945.png" alt="image-20220704071659945" style="zoom: 50%;" />

图中的蓝色方框部分即为所选的像素块，左上角坐标为（120，316），位于该视频的第 20 帧，即希望跟踪图中的白色大巴车。该汽车在第 20 帧出现，在第 150 帧消失，因此仅在这期间对汽车进行跟踪。

分别使用像素域匹配和离散余弦变换得到的频率域匹配两种匹配方式。对于两种方式，均以 MSE 作为相似度的评价指标，考虑到汽车运动速度并不快，相邻两帧之间移动并不多，这里仅在以上一时刻像素块为中心的九宫格内进行搜索，即 Wx=Wy=16，因为搜索范围很小，可以直接采取遍历搜索的方式寻找与目标最相似的区域。

对于两种匹配算法，计算每一帧对应的 MSE，绘出折线图如下：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704072556514.png" alt="image-20220704072556514" style="zoom:67%;" />

从上面的折线图中可以看出，随着时间的不断增加，两种匹配方式的误差都在不断增大，这是因为车辆所处的环境发生了变化，光线亮度等因素和刚开始的地点已经有了很大的不同。另外，在开始时基于像素域的匹配和基于频率域的匹配效果基本相同，但随着时间的推延，基于像素域的匹配效果更好一些，这是因为基于像素域的匹配的搜索指标和最终的评价指标一致，理论上说每一步都是搜索区域中 MSE 最小的区域。当然，如果搜索过程不是遍历搜索，那么情况也许会有所不同，因为这时基于像素域的搜索不能保证找到 MSE 最小的区域。

对于运动向量，这里根据助教的建议，在原始视频的基础上，添加运动向量为红色箭头，运动向量随帧数变化，形成一个新的视频（两种匹配方式都生成了视频，另外由于车辆运动速度不快，如果逐帧绘制运动向量，运动向量并不明显，因此这里每 10 帧绘制一次运动向量，也就是说，箭头所在的位置是目标块在 10 帧之后的位置）。下面是新视频中的其中一帧：（完整的视频在实验文件中）

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704072815692.png" alt="image-20220704072815692" style="zoom:50%;" />

在像素域匹配算法中，尝试只使用部分像素（偶数行且偶数列的像素）进行匹配，这样需要匹配的像素数量变为原来的 1/4，降低了算法的复杂度，以下是其与原始像素域匹配算法的精度比较：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704074049910.png" alt="image-20220704074049910" style="zoom:67%;" />

可以看到，只使用部分像素进行匹配时的误差较大，且处于水平震荡状态，这也是在预料之中的，当然，如果不能对搜索区域进行遍历，限制两种方式使用相同的搜索时间，那么使用部分像素进行匹配的算法也许会更胜一筹。

在频率域匹配算法中，尝试只使用部分系数（位于左上角的 1/4 块系数）进行匹配，那么这样需要匹配的元素个数同样变为原来的 1/4，降低了算法的复杂度，以下是其与原始频率域匹配算法的精度比较：

<img src="C:\Users\fanxiaoyu\AppData\Roaming\Typora\typora-user-images\image-20220704074540825.png" alt="image-20220704074540825" style="zoom:67%;" />

可以看到，只使用部分系数进行匹配时误差较大，这同样在预料之中。出乎预料的是，在接近末尾时，MSE 突然下降到与使用全部系数基本相同，可见对于最后一段时间，高频信号占比很小，于是两种匹配方式得到的结果基本相同。

除了上述评价图像相似度的方式，实际上也可以使用颜色分布直方图的方法来求两张图片之间的相似程度，这种方法在实验二中会有详细讨论，这里不再赘述。